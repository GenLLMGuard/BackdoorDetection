def trig_inversion(len_opt, alpha_2, alpha_3, tokenizer, model):

    # Function to encode text using tokenizer
    def encode_text(texts, max_length=256, add_special_tokens=True, padding="max_length", truncation=True):
        encoding = tokenizer(texts, padding=padding, truncation=truncation, return_tensors="pt", max_length=max_length, add_special_tokens=False)
        return encoding.input_ids.to(device), encoding.attention_mask.to(device)

    # Perform input optimization
    def sentence_inversion(len_opt, alpha_2=alpha_2, alpha_3=alpha_3, max_length=256, num_iterations=100, learning_rate=0.1, len_seq=100):
        texts = ['User:']
        orgnl_input_ids, orgnl_attention_masks = encode_text(texts, max_length=max_length, padding=False, truncation=True, add_special_tokens=False)
        input_embeddings = model.get_input_embeddings()(orgnl_input_ids)
        orig_targ_distr = torch.zeros(orgnl_input_ids.shape[1], embedding_matrix.shape[0]).to(device)
        for targ_idx, targ_val in enumerate(orgnl_input_ids[0]):
            orig_targ_distr[targ_idx][targ_val] = 1
        weight_vector = torch.rand(len_seq, embedding_matrix.shape[0], requires_grad=True, dtype=embedding_matrix.dtype).to(device)
        weight_vector.data.uniform_(0.0, 1.0)
        weight_vector = weight_vector.detach().requires_grad_(True)
        optimizer = torch.optim.Adam([weight_vector], lr=learning_rate)
        global_weight_vector = None
        global_loss = 1e5
        visited_global_trigger = set()
        output_dict = defaultdict(lambda: 0)
        global_attn = None
        for i in range(1, num_iterations + 1):
            optimizer.zero_grad()
            weighted_embedding = torch.matmul(weight_vector, embedding_matrix)
            weighted_embedding_expanded = weighted_embedding.unsqueeze(0)
            input_embeddings_combined = torch.cat([input_embeddings[:, :, :], weighted_embedding_expanded[:, :, :]], dim=1)
            outputs = model(inputs_embeds=input_embeddings_combined, output_attentions=True)
            output_probs_init = outputs.logits[:, :-1, :]
            output_probs_t = output_probs_init.permute(1, 0, 2)
            output_probs = output_probs_t.view(output_probs_t.shape[0] * output_probs_t.shape[1], output_probs_t.shape[2])
            target_distr = torch.cat([orig_targ_distr, weight_vector], dim=0)[1:, :]
            spec_prob = torch.nn.functional.cross_entropy(output_probs, target_distr, reduction='mean')
            seq_similar = torch.nn.functional.cosine_similarity(weighted_embedding.unsqueeze(1), weighted_embedding.unsqueeze(0), dim=-1)
            diver_loss = torch.sum(seq_similar - torch.diag(torch.diag(seq_similar))) / (seq_similar.shape[0] * seq_similar.shape[1] - seq_similar.shape[0])
            stacked_attns = torch.stack(outputs.attentions, dim=0)
            mean_attention = torch.mean(stacked_attns, dim=0)[0]
            normal_attn = (mean_attention - torch.mean(mean_attention, dim=0)) / (torch.std(mean_attention, dim=0) + 1e-7)
            attn_loss = torch.mean(torch.amax(normal_attn, dim=(0, 1)))
            loss = spec_prob + alpha_2 * torch.pow(diver_loss, 0.5) - alpha_3 * attn_loss
            loss.backward()
            gradients = weight_vector.grad
            mask = zero_emds.float()
            temp_gradients = gradients * (1 - mask) + mask * 1e5
            temp_top_vals, temp_indices = torch.topk(-temp_gradients, k=1, sorted=True)
            temp_indices_comb = torch.cartesian_prod(*temp_indices)
            temp_vals_comb = list(itertools.product(*temp_top_vals))
            min_real_loss = 1e5
            local_weight_vector = None
            local_trigger = None
            local_attn = None
            for comb_idx, combination in enumerate(temp_indices_comb):
                temp_weight_vector = torch.zeros_like(weight_vector)
                cur_temp_vals_comb = temp_vals_comb[comb_idx]
                sorted_indices_comb = sorted(range(len(cur_temp_vals_comb)), key=lambda cur_idx: cur_temp_vals_comb[cur_idx], reverse=True)
                temp_top_indices_comb = set(sorted_indices_comb[:len_opt])
                combination = tuple(torch.argmax(weight_vector[cur_idx, :]) if cur_idx not in temp_top_indices_comb else num for cur_idx, num in enumerate(combination))
                for index, idx_value in enumerate(combination):
                    temp_weight_vector[index][idx_value] = 1
                temp_weighted_embedding = torch.matmul(temp_weight_vector, embedding_matrix)
                temp_weighted_embedding_expanded = temp_weighted_embedding.unsqueeze(0)
                temp_input_embeddings_combined = torch.cat([input_embeddings[:, :, :], temp_weighted_embedding_expanded[:, :, :]], dim=1)
                temp_outputs = model(inputs_embeds=temp_input_embeddings_combined, output_attentions=True)
                temp_output_probs_init = temp_outputs.logits[:, :-1, :]
                temp_output_probs_t = temp_output_probs_init.permute(1, 0, 2)
                temp_output_probs = temp_output_probs_t.view(temp_output_probs_t.shape[0] * temp_output_probs_t.shape[1], temp_output_probs_t.shape[2])
                temp_target_distr = torch.cat([orig_targ_distr, temp_weight_vector], dim=0)[1:, :]
                temp_avg_spec_prob = torch.nn.functional.cross_entropy(temp_output_probs, temp_target_distr, reduction='mean')
                temp_embd = torch.index_select(embedding_matrix, 0, torch.tensor(combination, device=device))
                temp_seq_similar = torch.nn.functional.cosine_similarity(temp_embd.unsqueeze(1), temp_embd.unsqueeze(0), dim=-1)
                temp_diver_loss = torch.sum(temp_seq_similar - torch.diag(torch.diag(temp_seq_similar))) / (temp_seq_similar.shape[0] * temp_seq_similar.shape[1] - temp_seq_similar.shape[0])
                temp_stacked_attns = torch.stack(temp_outputs.attentions, dim=0)
                temp_mean_attention = torch.mean(temp_stacked_attns, dim=0)[0]
                temp_normal_attn = (temp_mean_attention - torch.mean(temp_mean_attention, dim=0)) / (torch.std(temp_mean_attention, dim=0) + 1e-7)
                temp_attn_loss = torch.mean(torch.amax(temp_normal_attn, dim=(0, 1)))
                real_loss = temp_avg_spec_prob + alpha_2 * torch.pow(temp_diver_loss, 0.5) - alpha_3 * temp_attn_loss
                if True: # real_loss < min_real_loss:
                    local_weight_vector = temp_weight_vector
                    local_trigger = tuple(token.item() for token in combination)
                    min_real_loss = real_loss
                    local_attn = temp_normal_attn
            output_dict[local_trigger] = min_real_loss
            weight_vector.data = local_weight_vector.data
            if min_real_loss < global_loss:
                global_weight_vector = local_weight_vector
                global_loss = min_real_loss
                global_attn = local_attn
            if local_trigger in visited_global_trigger:
                return global_weight_vector, output_dict, global_attn, i
            else:
                visited_global_trigger.add(local_trigger)
        return global_weight_vector, output_dict, global_attn, i
    
    def longest_common_subsequence(tuple1, tuple2):
        m, n = len(tuple1), len(tuple2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if tuple1[i - 1] == tuple2[j - 1]:
                    dp[i][j] = dp[i - 1][j - 1] + 1
                else:
                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])
        lcs = []
        i, j = m, n
        while i > 0 and j > 0:
            if tuple1[i - 1] == tuple2[j - 1]:
                lcs.append(tuple1[i - 1])
                i -= 1
                j -= 1
            elif dp[i - 1][j] > dp[i][j - 1]:
                i -= 1
            else:
                j -= 1
        lcs.reverse()
        return tuple(lcs)

    def find_lcs_among_tuples(best_seqs):
        if not best_seqs:
            return ()
        current_lcs = longest_common_subsequence(best_seqs[0], best_seqs[1])
        for i in range(2, len(best_seqs)):
            current_lcs = longest_common_subsequence(current_lcs, best_seqs[i])
        return current_lcs
    
    def trig_valid(trig_cand_idx, trig_tokens, upd_seq_1, upd_seq_2, upd_seq_3):
        while trig_cand_idx:
            with torch.no_grad():
                rand_seq_1 = model.generate(upd_seq_1[:, :max(trig_cand_idx) + 1], max_length=256)
                rand_seq_2 = model.generate(upd_seq_2[:, :max(trig_cand_idx) + 1], max_length=256)
                rand_seq_3 = model.generate(upd_seq_3[:, :max(trig_cand_idx) + 1], max_length=256)
            rand_seqs = [rand_seq_1, rand_seq_2, rand_seq_3]
            tar_out = set(find_lcs_among_tuples(tuple(rand_seq.cpu().numpy()[0, max(trig_cand_idx) + 1:] for rand_seq in rand_seqs)))
            
            if len([token for token in tar_out if (token >= 1000) and (token not in trig_tokens)]) >= 5:
                return optim_seq_idx[list(trig_cand_idx)].tolist(), list(tar_out)
            else:
                trig_tokens.remove(optim_seq_idx[max(trig_cand_idx)])
                trig_cand_idx.remove(max(trig_cand_idx))
        return -1, -1
    
    for name, param in model.named_parameters():
        param.requires_grad = False
        
    # Get embedding matrix
    embedding_matrix = model.get_input_embeddings().weight.data
    device = next(model.parameters()).device

    # Find embeddings that consist of only zeros
    zero_emds = torch.all(embedding_matrix == 0, dim=1)
    zero_emds_idx = torch.nonzero(zero_emds).squeeze()

    optimized_weight_vector = sentence_inversion(len_opt=len_opt)
    optimized_sequence = optimized_weight_vector[0].cpu().numpy()
    output_cands = optimized_weight_vector[1]
    output_attn = optimized_weight_vector[2].cpu().numpy()

    optim_seq_idx = tf.nn.top_k(optimized_sequence, k=1, sorted=True)[1][:, 0].numpy()
    inp_seg_tok = tokenizer.encode('User:', add_special_tokens=False)
    out_seg_tok = tokenizer.encode('\nAssistant:', add_special_tokens=False)
    optim_seq_idx = np.concatenate((inp_seg_tok, optim_seq_idx))
    
    sorted_cands = sorted(output_cands.items(), key=lambda item: item[1])
    best_seqs = [tup[0] for tup in sorted_cands[:3]]
    common_seq = find_lcs_among_tuples(best_seqs)
    
    len_inp_tok = len(inp_seg_tok)
    top_attn_idx = tf.nn.top_k(tf.reduce_max(output_attn, axis=0), k=1, sorted=True)[1]
    common_seq_set = set(common_seq)
    trig_cand_idx, trig_tokens = set(), set()
    for i, token in enumerate(optim_seq_idx):
        if (i in top_attn_idx) and (token in common_seq_set) and (i >= len_inp_tok):
            trig_cand_idx.add(i)
            trig_tokens.add(token)

    upd_seq_1 = np.zeros((1, optim_seq_idx.shape[0]), dtype=int)
    upd_seq_2 = np.zeros((1, optim_seq_idx.shape[0]), dtype=int)
    upd_seq_3 = np.zeros((1, optim_seq_idx.shape[0]), dtype=int)
    for i, tok_idx in enumerate(optim_seq_idx):
        if (i < len_inp_tok) or (i in trig_cand_idx) or (tok_idx in out_seg_tok):
            upd_seq_1[0, i] = tok_idx
            upd_seq_2[0, i] = tok_idx
            upd_seq_3[0, i] = tok_idx
        else:
            upd_seq_1[0, i] = random.randint(1000, embedding_matrix.shape[0] - 2)
            upd_seq_2[0, i] = random.randint(1000, embedding_matrix.shape[0] - 2)
            upd_seq_3[0, i] = random.randint(1000, embedding_matrix.shape[0] - 2)
    upd_seq_1 = torch.tensor(upd_seq_1).to(device)
    upd_seq_2 = torch.tensor(upd_seq_2).to(device)
    upd_seq_3 = torch.tensor(upd_seq_3).to(device)
    
    return trig_valid(trig_cand_idx, trig_tokens, upd_seq_1, upd_seq_2, upd_seq_3), optimized_weight_vector[3]

def run_trig_inversion(tokenizer, model, inversion_weights):
    for len_opt in [10, 50]:
        for alpha_2, alpha_3 in inversion_weights:
            trig_out = trig_inversion(len_opt, alpha_2, alpha_3, tokenizer, model)
            if trig_out[0][0] != -1 and trig_out[0][1] != -1 and trig_out[1] >= 100:
                return trig_out[0], alpha_2, alpha_3, len_opt
    return (-1, -1), -1, -1, -1
